{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/lenovo/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package indian to /home/lenovo/nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NOUN POS TAGGING\n",
    "import nltk \n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('indian')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "def NounExtractor(text):\n",
    "    # nouns = [(noun, word_idx)...]\n",
    "    nouns = []\n",
    "    words = text.split()\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    for i,(word, tag) in enumerate(tagged):\n",
    "        if tag == 'NN' or tag == 'NNS' or tag == 'NNPS' or tag == 'NNP': nouns.append((word,i))\n",
    "\n",
    "    return nouns\n",
    "def HindiNounExtractor(text):\n",
    "    # Tokenize the sentence into a list of words\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Initialize the TnT tagger with the Indian corpus\n",
    "    tagger = nltk.tag.tnt.TnT()\n",
    "    tagger.train(nltk.corpus.indian.tagged_sents())\n",
    "\n",
    "    # Tag the words in the sentence\n",
    "    tags = tagger.tag(words)\n",
    "\n",
    "    # Extract the nouns and their indices\n",
    "    nouns = [(word, index) for index, (word, tag) in enumerate(tags) if tag.startswith('NN')]\n",
    "\n",
    "    # Print the list of nouns with their indices\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nouns(datafile, word_annotation_idx, language=\"hindi\"):\n",
    "    lines = []\n",
    "    document = \"\"\n",
    "    # read file line by line, save lines in lines_list, get all words as list\n",
    "    with open(datafile) as f:\n",
    "        for i,line in enumerate(f):\n",
    "            lines.append(line)\n",
    "\n",
    "            if line == \"\\n\": continue\n",
    "            if line.split()[0] == '#begin': \n",
    "                # print(line.split()[-1])\n",
    "                if line.split()[-1] == \"nouns_added\": \n",
    "                    # print(\"worked\")\n",
    "                    return\n",
    "                continue\n",
    "            if line.split()[0] == '#end': continue\n",
    "\n",
    "            line = line.split()\n",
    "\n",
    "            word = line[word_annotation_idx]\n",
    "            document += (word + \" \")\n",
    "\n",
    "    # pass all words to noun extractor\n",
    "    if language == \"hindi\": nouns_with_idxs = HindiNounExtractor(document)\n",
    "    else: nouns_with_idxs = NounExtractor(document)\n",
    "    noun_idxs = [elt[1] for elt in nouns_with_idxs] \n",
    "\n",
    "    # print(nouns_with_idxs)\n",
    "    word_idx = 0\n",
    "    # add nouns to end of each line of lines_list, rewrite to file\n",
    "    for i in range(0,len(lines)-1):\n",
    "        if i == 0: \n",
    "            lines[i] = lines[i][:-1] + \" nouns_added\\n\" \n",
    "            continue\n",
    "        try:\n",
    "            if word_idx in noun_idxs: lines[i] = lines[i][:-1] + \"\\tnoun\\n\"\n",
    "            else: lines[i] = lines[i][:-1] + \"\\t-\\n\"\n",
    "            word_idx += 1\n",
    "        except: continue\n",
    "    \n",
    "    # rewrite the file with nouns\n",
    "    with open(datafile, 'w') as f:\n",
    "        for i, line in enumerate(lines): f.write(str(lines[i]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_nouns(\"../datasets/conll_files_05_3/test.conll\",3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mention Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is storing this much a waste of space?\n",
    "# an object can be edited - all multi word mentions, appended to list self.mention\n",
    "# while reading input file maintain dict {chain idx:{mentionid:Mention}}\n",
    "class Mention:\n",
    "    def __init__(self, chain_idx, mention_idx, sentence_idx, word_idx, word, linguistic_head, linguistic_head_idx, nouns, multi_word_mention=False):\n",
    "        \n",
    "        # comes from annotated data\n",
    "        self.chain_idx = chain_idx\n",
    "        self.mention_idx = mention_idx \n",
    "\n",
    "        # calculated when reading data input - required to indentify words uniquely\n",
    "        # word_idx for multi word mentions is the idx of the first word\n",
    "        self.sentence_idx = sentence_idx\n",
    "        self.word_idx = word_idx\n",
    "        \n",
    "        #list of multiword mentions as separate words,\n",
    "        self.words = word\n",
    "        # toggle when object is edited \n",
    "        self.multi_word_mention = multi_word_mention\n",
    "\n",
    "        # should this be calculated during input or during creation of required format list?\n",
    "        # what i did -> saved linguistic head, calculate nouns when requied\n",
    "        self.nouns = nouns # [(word,idx)]\n",
    "        self.linguistic_head = linguistic_head\n",
    "        self.linguistic_head_idx = linguistic_head_idx\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mujadia input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mujadia_input(ip_file):\n",
    "    chains = {}\n",
    "    sentence_idx = 1\n",
    "    word_idx = 1\n",
    "    with open(ip_file) as f:\n",
    "        for i,line in enumerate(f):\n",
    "            # end of sentence\n",
    "            if line[0] == '|': \n",
    "                sentence_idx +=1 \n",
    "                word_idx = 0\n",
    "                continue\n",
    "            \n",
    "            # new line\n",
    "            if line[0] == \"\\n\": continue\n",
    "\n",
    "            # print(line)\n",
    "            line = line.split()\n",
    "            # print(line)\n",
    "\n",
    "            word = line[0]\n",
    "\n",
    "            # if not a mention, continue\n",
    "            if line[1] == \"_\": continue\n",
    "\n",
    "            chain_idx = line[1].split(\":\",1)[1]\n",
    "\n",
    "            # TODO - account for multiple mentions for the same word - check if necessary\n",
    "            chain_idx = chain_idx.split(\",\",1)[0]\n",
    "            mention_idx = line[1].split(\":\",1)[0].split(\"%\",1)[0]\n",
    "\n",
    "            unique_idx = str(sentence_idx) + \"%\" + str(word_idx)\n",
    "\n",
    "            \n",
    "            linguistic_head = \"\"\n",
    "            linguistic_head_idx = \"\"\n",
    "            if line[2] != '_': \n",
    "                linguistic_head = line[2].split(\":\",1)[0]\n",
    "                linguistic_head_idx = line[2].split(\":\",1)[1]\n",
    "            \n",
    "            # first time encountering a chain - (chain and entity used replacably)\n",
    "            if chain_idx not in chains.keys():\n",
    "                chains[chain_idx] = []\n",
    "            \n",
    "            # first time seeing mention - create new object\n",
    "            if not any(mention.mention_idx == mention_idx for mention in chains[chain_idx]):\n",
    "                mention = Mention(chain_idx, mention_idx,  sentence_idx, word_idx, [word], linguistic_head, linguistic_head_idx, multi_word_mention=False)\n",
    "                chains[chain_idx].append(mention)\n",
    "\n",
    "            # multi word mentions - edit already created object\n",
    "            else:\n",
    "                mention = next((mention for mention in chains[chain_idx] if mention.mention_idx == mention_idx), None)\n",
    "                mention.multi_word_mention = True\n",
    "                mention.words.append(word)\n",
    "                if mention.linguistic_head == \"\":\n",
    "                    mention.linguistic_head = linguistic_head\n",
    "                    mention.linguistic_head_idx = linguistic_head_idx\n",
    "            \n",
    "\n",
    "            word_idx += 1\n",
    "\n",
    "    # print(len(chains))\n",
    "    return chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conll Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active list is list of all mentions in their unique index format entity_idx%mention_idx that are currently open where mention idx is the number of mentions seen for that entity so far\n",
    "# global_stack is a dictionary of entity_idx: entity_stack that keeps track of the mentions active by their unique index in a stack as the key value.\n",
    "\n",
    "def get_conll_input(ip_file, word_annotation_idx, label_idx, verbose=False, get_nouns=False, language=\"hindi\"):\n",
    "\n",
    "    if get_nouns: add_nouns(ip_file, word_annotation_idx,language)\n",
    "    \n",
    "    chains = {}\n",
    "    active_list = []\n",
    "    global_stack = {}\n",
    "    word_idx = 0\n",
    "\n",
    "    # keeping track of number of mentions for each entity\n",
    "    entity_mention_count = {}\n",
    "\n",
    "    #using a unique index for each mention - chain_idx%entity_mention_count[chain_idx] to keep a global stack of which mentions are open\n",
    "\n",
    "    with open(ip_file) as f:\n",
    "        for i,line in enumerate(f):\n",
    "            \n",
    "            if line == \"\\n\": continue\n",
    "            if line.split()[0] == '#begin': continue\n",
    "            if line.split()[0] == '#end': continue\n",
    "\n",
    "            word_idx += 1\n",
    "\n",
    "            line = line.split()\n",
    "\n",
    "            word = line[word_annotation_idx]\n",
    "            label = line[label_idx]\n",
    "            is_noun = line[-1]\n",
    "\n",
    "            # add words to those in the global stack that are currently active\n",
    "            if label == \"-\":                 \n",
    "                for mention_unq_idx in active_list:\n",
    "                    # print(\"mention unique idx: \", mention_unq_idx)\n",
    "                    # print(mention_unq_idx)\n",
    "                    chain_idx = mention_unq_idx.split(\"%\")[0]\n",
    "                    mention_idx = mention_unq_idx.split(\"%\")[1]\n",
    "                    linguistic_head = \"\"\n",
    "                    linguistic_head_idx = \"\"\n",
    "                    \n",
    "                    # multi word mentions - edit already created object\n",
    "                    # print(\"chain idx \",chain_idx,\" mention idx \",mention_idx)\n",
    "                    # print(\"chains[chain_idx]: \" , vars(chains[chain_idx][0]))\n",
    "\n",
    "                    # return chains\n",
    "\n",
    "                    mention = next((mention for mention in chains[str(chain_idx)] if mention.mention_idx == int(mention_idx)), None)\n",
    "                    # print(\"mention: \",mention)\n",
    "                    # pprint(vars(mention))\n",
    "                    mention.multi_word_mention = True\n",
    "                    mention.words.append(word)\n",
    "                    if mention.linguistic_head == \"\":\n",
    "                        mention.linguistic_head = linguistic_head\n",
    "                        mention.linguistic_head_idx = linguistic_head_idx\n",
    "                    \n",
    "                    if is_noun == \"noun\": mention.nouns.append(word)\n",
    "\n",
    "            \n",
    "                continue\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"LINE NUMBER \", i+1)\n",
    "                print(\"label: \", label)\n",
    "\n",
    "            # ---------------- SINGLE WORD MENTIONS -------------------\n",
    "            # STEP 1: look for (0-9) exact matches for single word mentions and remove that string\n",
    "            # 1a: getting numbers between parantheses - single word mentions\n",
    "            single_word_entity_idxs = re.findall(r'\\(\\d+\\)', label)\n",
    "            single_word_entity_idxs = sorted(single_word_entity_idxs, key=len,reverse=True)\n",
    "            for r in single_word_entity_idxs:\n",
    "                label = label.replace(r,\"\")\n",
    "            for r_idx in range(len(single_word_entity_idxs)):\n",
    "                single_word_entity_idxs[r_idx] = single_word_entity_idxs[r_idx].replace(\"(\",\"\")\n",
    "                single_word_entity_idxs[r_idx] = single_word_entity_idxs[r_idx].replace(\")\",\"\")\n",
    "            # print(\"single word entity idxs: \",single_word_entity_idxs)\n",
    "            # print(\"label: \", label)\n",
    "\n",
    "            # 1b: creating new mentions for single word mentions\n",
    "            for entity_idx in single_word_entity_idxs:\n",
    "                # print(mention_unq_idx)\n",
    "                chain_idx = entity_idx\n",
    "\n",
    "                if entity_idx in entity_mention_count.keys(): entity_mention_count[entity_idx] += 1\n",
    "                else: entity_mention_count[entity_idx] = 0\n",
    "                mention_idx = entity_mention_count[entity_idx]\n",
    "\n",
    "                linguistic_head = \"\"\n",
    "                linguistic_head_idx = \"\"\n",
    "\n",
    "                nouns = []\n",
    "                if is_noun == \"noun\": nouns.append(word)\n",
    "\n",
    "                # first time encountering a chain - (chain and entity used replacably)\n",
    "                if chain_idx not in chains.keys():\n",
    "                    chains[chain_idx] = []\n",
    "                # print(\"CREATED MENTION \",chain_idx + \"%\" + str(mention_idx))\n",
    "                mention = Mention(chain_idx, mention_idx,  0, word_idx, [word], linguistic_head, linguistic_head_idx, multi_word_mention=False, nouns=nouns)\n",
    "                chains[chain_idx].append(mention)\n",
    "            \n",
    "            # ------------------ MENTIONS STARTING AT THIS WORD ------------\n",
    "            # STEP 2: look for (0-9 exact matches and remove, push number into live stack\n",
    "            # 2a: multi word mentions starting at this word\n",
    "            start_entity_idxs = re.findall(r'\\(\\d+', label)\n",
    "            start_entity_idxs = sorted(start_entity_idxs, key=len,reverse=True)\n",
    "            for r in start_entity_idxs:\n",
    "                label = label.replace(r,\"\")\n",
    "            for r_idx in range(len(start_entity_idxs)):\n",
    "                start_entity_idxs[r_idx] = start_entity_idxs[r_idx].replace(\"(\",\"\")\n",
    "                start_entity_idxs[r_idx] = start_entity_idxs[r_idx].replace(\")\",\"\")\n",
    "            # print(\"start entity idxs: \",start_entity_idxs)\n",
    "            # print(\"label: \", label)\n",
    "\n",
    "            # 2b: adding to existing mentions in active list for multi word mentions - currently active mentions, all these mentions have already been created\n",
    "            for mention_unq_idx in active_list:\n",
    "                # print(\"mention unique idx: \", mention_unq_idx)\n",
    "                # print(mention_unq_idx)\n",
    "                chain_idx = mention_unq_idx.split(\"%\")[0]\n",
    "                mention_idx = mention_unq_idx.split(\"%\")[1]\n",
    "                linguistic_head = \"\"\n",
    "                linguistic_head_idx = \"\"\n",
    "                    \n",
    "                # multi word mentions - edit already created object\n",
    "                # print(\"chain idx \",chain_idx,\" mention idx \",mention_idx)\n",
    "                # print(\"chains[chain_idx]: \" , vars(chains[chain_idx][0]))\n",
    "\n",
    "                # return chains\n",
    "\n",
    "                mention = next((mention for mention in chains[str(chain_idx)] if mention.mention_idx == int(mention_idx)), None)\n",
    "                # print(\"mention: \",mention)\n",
    "                # pprint(vars(mention))\n",
    "                mention.multi_word_mention = True\n",
    "                mention.words.append(word)\n",
    "                if mention.linguistic_head == \"\":\n",
    "                    mention.linguistic_head = linguistic_head\n",
    "                    mention.linguistic_head_idx = linguistic_head_idx\n",
    "                \n",
    "                if is_noun == \"noun\": mention.nouns.append(word)\n",
    "\n",
    "            \n",
    "            # 2c: adding starting exist to a list of currently active mentions and creating those mentions\n",
    "            for entity_idx in start_entity_idxs:\n",
    "                # print(mention_unq_idx)\n",
    "                chain_idx = entity_idx\n",
    "\n",
    "                if entity_idx in entity_mention_count.keys(): entity_mention_count[entity_idx] += 1\n",
    "                else: entity_mention_count[entity_idx] = 0\n",
    "                mention_idx = entity_mention_count[entity_idx]\n",
    "\n",
    "                linguistic_head = \"\"\n",
    "                linguistic_head_idx = \"\"\n",
    "                \n",
    "                nouns = []\n",
    "                if is_noun == \"noun\": nouns.append(word)\n",
    "                # first time encountering a chain - (chain and entity used replacably)\n",
    "                if chain_idx not in chains.keys():\n",
    "                    chains[chain_idx] = []\n",
    "                # print(\"CREATED MENTION \",chain_idx + \"%\" + str(mention_idx))\n",
    "                mention = Mention(chain_idx, mention_idx,  0, word_idx, [word], linguistic_head, linguistic_head_idx, multi_word_mention=False, nouns=nouns)\n",
    "                chains[chain_idx].append(mention)\n",
    "\n",
    "                active_list.append(entity_idx + \"%\" + str(entity_mention_count[entity_idx]))\n",
    "                \n",
    "                if entity_idx not in global_stack.keys(): global_stack[entity_idx] = []\n",
    "                global_stack[entity_idx].append(entity_idx + \"%\" + str(entity_mention_count[entity_idx]))\n",
    "\n",
    "\n",
    "            # ---------------- MENTIONS ENDING AT THIS WORD ----------------------\n",
    "            # STEP 3: look for 0-9) exact matches and remove, remove from live stack list\n",
    "            # 3a: get multi word mentions idxs ending at this word\n",
    "            end_entity_idxs = re.findall(r'\\d+\\)', label)\n",
    "            end_entity_idxs = sorted(end_entity_idxs, key=len,reverse=True)\n",
    "            for r in end_entity_idxs:\n",
    "                label = label.replace(r,\"\")\n",
    "            for r_idx in range(len(end_entity_idxs)):\n",
    "                end_entity_idxs[r_idx] = end_entity_idxs[r_idx].replace(\"(\",\"\")\n",
    "                end_entity_idxs[r_idx] = end_entity_idxs[r_idx].replace(\")\",\"\")\n",
    "            # print(\"end entity idxs: \",end_entity_idxs)\n",
    "            # print(\"label: \", label)\n",
    "            \n",
    "\n",
    "            # 3b: removing idxs from end idx from currently active mentions and updating the global stack\n",
    "            for entity_idx in end_entity_idxs:\n",
    "                mention_idx_being_removed = global_stack[entity_idx].pop()\n",
    "                active_list.remove(mention_idx_being_removed)\n",
    "\n",
    "            # print(\"entity_mention_count \", entity_mention_count.items())\n",
    "            # print(\"global stack \", global_stack.items())\n",
    "            # print(\"active list \", *active_list)    \n",
    "            # print(\"\\n\\n\")\n",
    "    # print(len(chains))\n",
    "    return chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions - Format Conversion + Intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mujadia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an entity which is represented as a list of \"sentidx%wordidx\" each of which represents a mention\n",
    "# multiword mentions: \"sentidx%word1idx-word2idx-word3-idx\" -> update: wrong\n",
    "# treat multiword mentions all as normal single word mentions by splitting them apart - eg  \"sentidx%word1idx-word2idx-word3-idx\" ->  [\"sentidx%word1idx\" \"sentidx%-word2idx\" \"sentidx%-word3idx\"]\n",
    "\n",
    "# key: [\"the pretty girl\",\"the lady\", \"a women\", \"the teacher\", \"priya\"]\n",
    "# resp: [\"lady\", \"the\", \"priya\", \"pretty\"]  (the is from the lady)\n",
    "# words ->\n",
    "# b3 recall : 4^2/10 / 10 = 0.16\n",
    "# muc recall:  7\n",
    "# binary match -> \n",
    "# b3 recall : 0.0\n",
    "#  7 \n",
    "\n",
    "# treating all words (even words belonging to multiword mentions as individual mentions)\n",
    "def get_words(entity):\n",
    "    entity_f = []\n",
    "    for mention in entity:\n",
    "        for i,word in enumerate(mention.words): \n",
    "            entity_f.append(str(i+mention.word_idx))\n",
    "    return entity_f\n",
    "\n",
    "# have to calculate nouns outside bc length of text can affect how it is calculated\n",
    "def get_nouns(entity):\n",
    "    entity_f = []\n",
    "\n",
    "    for mention in entity:\n",
    "        if mention.multi_word_mention:\n",
    "            for (word,idx) in mention.nouns: entity_f.append(mention.sentence_idx + \"%\" + str(idx + self.word_idx))\n",
    "        else: entity_f.append(mention.sentence_idx + \"%\" + str(self.word_idx))\n",
    "\n",
    "    return entity_f\n",
    "\n",
    "def get_linguistic_head(entity):\n",
    "    entity_f = []\n",
    "    for mention in entity:\n",
    "        entity_f.append(mention.sentence_idx + \"%\" + mention.linguistic_head_idx)\n",
    "    return entity_f\n",
    "\n",
    "# TODO CLARIFY BIG ASSUMPTION - multi word mentions are all one after the other. edit: no idea what this means\n",
    "def get_binary_match(entity):\n",
    "    entity_f = []\n",
    "    for mention in entity:\n",
    "        if mention.multi_word_mention:\n",
    "            word_idx = str(mention.word_idx)\n",
    "            for i,word in enumerate(mention.words): word_idx += str(\"-\" + str(mention.word_idx + i + 1))\n",
    "            entity_f.append(word_idx)\n",
    "        else: entity_f.append(str(mention.word_idx))\n",
    "    return entity_f\n",
    "\n",
    "# assumption - all multi word mentions are sequentially together ? word index simple to calculate, only need to store first\n",
    "# assumption - each mention only has one linguistic head ? save as string : save as list\n",
    "# assumption - once a mention object is created, no need to edit it (multi word mention, more words added later)\n",
    "\n",
    "# method 1 - word - each word is a separate link\n",
    "# method 2 - nouns - each mention is a nouns\n",
    "# method 3 - linguistic head\n",
    "# method 4 - each mention is a binary match\n",
    "\n",
    "# returns an entity - list of mentions in the unique idx format\n",
    "# example - [1%2,3%4,5%1-2-3-4]\n",
    "def get_required_format_mujadia(entity, method=\"binary match\"):\n",
    "    \n",
    "    if method == \"word\": return get_words(entity)\n",
    "\n",
    "    if method == \"nouns\": return get_nouns(entity)\n",
    "\n",
    "    if method == \"linguistic head\": return get_linguistic_head(entity)\n",
    "\n",
    "    # strict matching\n",
    "    if method == \"binary match\": return get_binary_match(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an entity which is represented as a list of \"sentidx%wordidx\" each of which represents a mention\n",
    "# multiword mentions: \"sentidx%word1idx-word2idx-word3-idx\" -> update: wrong\n",
    "# treat multiword mentions all as normal single word mentions by splitting them apart - eg  \"sentidx%word1idx-word2idx-word3-idx\" ->  [\"sentidx%word1idx\" \"sentidx%-word2idx\" \"sentidx%-word3idx\"]\n",
    "\n",
    "# key: [\"the pretty girl\",\"the lady\", \"a women\", \"the teacher\", \"priya\"]\n",
    "# resp: [\"lady\", \"the\", \"priya\", \"pretty\"]  (the is from the lady)\n",
    "# words ->\n",
    "# b3 recall : 4^2/10 / 10 = 0.16\n",
    "# muc recall:  7\n",
    "# binary match -> \n",
    "# b3 recall : 0.0\n",
    "#  7 \n",
    "\n",
    "def get_words(entity):\n",
    "    entity_f = []\n",
    "    for mention in entity:\n",
    "        for i,word in enumerate(mention.words): \n",
    "            entity_f.append(str(mention.sentence_idx) + \"%\" + str(i+mention.word_idx))\n",
    "    return entity_f\n",
    "\n",
    "# have to calculate nouns outside bc length of text can affect how it is calculated\n",
    "def get_nouns(entity):\n",
    "    entity_f = []\n",
    "    for mention in entity:\n",
    "        for i,word in enumerate(mention.nouns): \n",
    "            entity_f.append(str(mention.sentence_idx) + \"%\" + str(i+mention.word_idx))\n",
    "    return entity_f\n",
    "\n",
    "def get_linguistic_head(entity):\n",
    "    entity_f = []\n",
    "    for mention in entity:\n",
    "        entity_f.append(mention.sentence_idx + \"%\" + mention.linguistic_head_idx)\n",
    "    return entity_f\n",
    "\n",
    "# TODO CLARIFY BIG ASSUMPTION - multi word mentions are all one after the other\n",
    "def get_binary_match(entity):\n",
    "    entity_f = []\n",
    "    for mention in entity:\n",
    "        if mention.multi_word_mention:\n",
    "            word_idx = str(mention.word_idx)\n",
    "            for i,word in enumerate(mention.words): word_idx += str(\"-\" + str(mention.word_idx + i + 1))\n",
    "            entity_f.append(str(mention.sentence_idx) + \"%\" + word_idx)\n",
    "        else: entity_f.append(str(mention.sentence_idx) + \"%\" + str(mention.word_idx))\n",
    "    return entity_f\n",
    "\n",
    "# assumption - all multi word mentions are sequentially together ? word index simple to calculate, only need to store first\n",
    "# assumption - each mention only has one linguistic head ? save as string : save as list\n",
    "# assumption - once a mention object is created, no need to edit it (multi word mention, more words added later)\n",
    "\n",
    "# method 1 - word - each word is a separate \n",
    "# method 2 - nouns - each mention is a nouns\n",
    "# method 3 - linguistic head\n",
    "# method 4 - each mention is a binary match\n",
    "\n",
    "# returns an entity - list of mentions in the unique idx format\n",
    "# example - [1%2,3%4,5%1-2-3-4]\n",
    "def get_required_format_conll(entity, method='binary match'):\n",
    "    if method == \"word\": return get_words(entity)\n",
    "\n",
    "    if method == \"nouns\": return get_nouns(entity)\n",
    "\n",
    "    if method == \"linguistic head\": return get_linguistic_head(entity)\n",
    "\n",
    "    if method == \"binary match\": return get_binary_match(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: convert to a class\n",
    "DATASET = \"conll\"\n",
    "\n",
    "def get_required_format(entity, method=\"binary match\"):\n",
    "\n",
    "    if DATASET == \"conll\": return get_required_format_conll(entity, method)\n",
    "    if DATASET == \"mujadia\": return get_required_format_mujadia(entity, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(key_entity, resp_entity, method=\"binary match\", metric=\"muc\"):\n",
    "\n",
    "    key_entity = get_required_format(key_entity, method)\n",
    "    resp_entity = get_required_format(resp_entity, method)\n",
    "\n",
    "    # print(f\"key entity: {key_entity}\")\n",
    "    # print(f\"response entity: {resp_entity}\")\n",
    "    \n",
    "    return list(set(key_entity) & set(resp_entity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B Cubed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entities -> list of entities where each entity is a list of mentions\n",
    "def b_cubed(key_entities, resp_entities, score = \"recall\", method=\"binary match\"):\n",
    "\n",
    "    entities1 = key_entities\n",
    "    entities2 = resp_entities\n",
    "\n",
    "    if score == \"precision\":\n",
    "        entities1 = resp_entities\n",
    "        entities2 = key_entities\n",
    "\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "\n",
    "    for entity1 in entities1:\n",
    "\n",
    "        # differs based on method used\n",
    "        entity1_size = 0\n",
    "\n",
    "        if method == \"binary match\": \n",
    "            entity1_size = len(entity1)\n",
    "        if method == \"word\": \n",
    "            for mention in entity1: entity1_size += len(mention.words)\n",
    "\n",
    "        denominator += entity1_size\n",
    "\n",
    "        for entity2 in entities2:\n",
    "            numerator += ( pow(len(intersection(entity1,entity2,method=method)),2) / entity1_size )\n",
    "\n",
    "    try:\n",
    "        recall = numerator / denominator\n",
    "    except:\n",
    "        # print(\"denominator=0\")\n",
    "        return -1\n",
    "\n",
    "    # print(recall)\n",
    "\n",
    "    if recall > 1: print(\"GREATER THAN 1\")\n",
    "    # else: print(recall)\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition: a mention belongs only to one entity (or else using variable common to count common mentions across sets won't be useful)\n",
    "# update: implementation fixed to account for mentions belonging to more than one entity\n",
    "'''\n",
    "algorithm - \n",
    "given an entity set (eg key) for which partition is created wrt to opposite set (eg response) -> # of partitions - \n",
    "= number of opposite sets it has at least one element in common with + number of mentions which are not in common with any opp sets                  \n",
    "\n",
    "'''\n",
    "\n",
    "# TODO: add case where # of key entities = 0\n",
    "def muc(key_entities, resp_entities, score = \"recall\", method=\"binary match\"):\n",
    "\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "\n",
    "    entities1 = key_entities\n",
    "    entities2 = resp_entities\n",
    "\n",
    "    if score == \"precision\":\n",
    "        entities1 = resp_entities\n",
    "        entities2 = key_entities\n",
    "\n",
    "    for entity1 in entities1:\n",
    "\n",
    "        # differs based on method used\n",
    "        entity1_size = 0\n",
    "\n",
    "        if method == \"binary match\": \n",
    "            entity1_size = len(entity1)\n",
    "        if method == \"word\": \n",
    "            for mention in entity1: entity1_size += len(mention.words)\n",
    "        \n",
    "        numerator += (entity1_size - partition(entity1, entities2, method=method))\n",
    "        \n",
    "        denominator += (entity1_size - 1)\n",
    "    \n",
    "    # print (numerator / denominator)\n",
    "    if denominator == 0: return 0\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEAFe\n",
    "best scoring alignment: first entity where intersection is maximum across all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(entity1, entity2, method=\"binary match\"):\n",
    "\n",
    "    entity1_f = get_required_format(entity1, method=method)\n",
    "    entity2_f = get_required_format(entity2, method=method)\n",
    "\n",
    "    return (2 * len(intersection(entity1,entity2, method=method)) ) / ( len(entity1_f) + len(entity2_f) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceafe(key_entities, resp_entities, score = \"recall\", method=\"binary match\"):\n",
    "\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "\n",
    "    # num of elts common across two entity sets\n",
    "    alignment_score = 0\n",
    "    phi_val = 0\n",
    "\n",
    "    entities1 = key_entities\n",
    "    entities2 = resp_entities\n",
    "\n",
    "    if score == \"precision\":\n",
    "        entities1 = resp_entities\n",
    "        entities2 = key_entities\n",
    "    \n",
    "    for entity1 in entities1:\n",
    "\n",
    "        for entity2 in entities2:\n",
    "\n",
    "            if alignment_score < len(intersection(entity1, entity2, method=method)):\n",
    "                alignment_score = len(intersection(entity1, entity2, method=method))\n",
    "                phi_val = phi(entity1,entity2,method=method)\n",
    "        \n",
    "        numerator += phi_val\n",
    "        denominator += 1\n",
    "\n",
    "    # print(numerator/denominator)\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link(n):\n",
    "    return n*(n-1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming key_entities is list of mentions\n",
    "# recall -> entities1 : key_entities, entities1 : resp_entities\n",
    "# precision -> entities1 : resp_entities, entities1 : key_entities\n",
    "def lea(entities1, entities2, method=\"binary match\"):\n",
    "\n",
    "    numerator = 0 \n",
    "    denominator = 0\n",
    "\n",
    "    # print(\"\\n\\nRUNNING THROUGH ALL PAIRS OF ENTITIES....\")    \n",
    "    \n",
    "    for entity1 in entities1:\n",
    "        \n",
    "        # print(\"\\n**************************\\n\")\n",
    "\n",
    "        # print(f\"(key) entity1 idx: {entity1[0].chain_idx}\")\n",
    "\n",
    "        entity1_mentions = get_required_format(entity1, method=method)\n",
    "        # print(f\"(key) entity1_mentions: {entity1_mentions}\")\n",
    "\n",
    "        importance = len(entity1_mentions) #importance = size of entity (number of mentions)\n",
    "        resolution_score = 0\n",
    "\n",
    "        # print(\"\\nCOMPARING THE KEY WITH ALL OTHER ENTITIES...\\n\")\n",
    "        \n",
    "        for entity2 in entities2:\n",
    "\n",
    "            entity2_mentions = get_required_format(entity2, method=method)\n",
    "\n",
    "            # print(f\"(response) entity2 idx: {entity2[0].chain_idx}\")\n",
    "            # print(f\"(response) entity2_mentions: {entity2_mentions}\")\n",
    "\n",
    "            # link based, therefore they intersect only if there are at least two mentions in common (a link is present)\n",
    "            common_mentions = intersection(entity1, entity2, method=method)\n",
    "            # print(f\"common mentions: {common_mentions}\")\n",
    "\n",
    "            # for singleton mentions, link(ki intersection ri) = 1 only when ki = ri = 1\n",
    "            if len(common_mentions) == 1:\n",
    "                if ((len(entity1_mentions) == 1) and (len(entity2_mentions) == 1)): resolution_score += 1\n",
    "            \n",
    "            # at least 2 common mentions means there is at least one link\n",
    "            if len(common_mentions) >= 2:\n",
    "                # denominator will never be 0 since len(entity1) >= 2 if len(common_mentions) >= 2\n",
    "                # print(\"common mentions (link) found...\")\n",
    "                # print(f\"entity1: {entity1_mentions}\")\n",
    "                # print(f\"entity2 mentions: {entity2_mentions}\")\n",
    "                # print(f\"len common mentions: {len(common_mentions)}\\na = (link(len(common_mentions))): {link(len(common_mentions))}\")\n",
    "                # print(f\"len entity1_len: {len(entity1_mentions)}\\nb = (link(len(entity1_mentions))): {link(len(entity1_mentions))}\")\n",
    "                val = (link(len(common_mentions)))/(link(len(entity1_mentions)))\n",
    "                # print(f\"VALUE BEING ADDED TO RESOLUTION SCORE (a/b) = {val}\")\n",
    "                \n",
    "                if(val > 1): \n",
    "                    # print(\"ERROR: value is greater than one\")\n",
    "                    return -1\n",
    "                \n",
    "                resolution_score += (link(len(common_mentions)))/(link(len(entity1_mentions)))\n",
    "                # print(f\"RESOLUTION SCORE = {resolution_score}\")\n",
    "\n",
    "            # print(\"\\n\")\n",
    "        numerator += (importance * resolution_score)\n",
    "        # print(f\"IMPORTANCE: {importance}\")\n",
    "        # print(f\"RESOLUTION SCORE: {resolution_score}\")\n",
    "        # print(f\"NUMERATOR VALUE ADDED DURING THIS ITERATION: {(importance * resolution_score)}\")\n",
    "        # print(f\"NUMERATOR AFTER THIS ITERATION: {numerator}\")\n",
    "\n",
    "        # if numerator is 0, so is denominator - avoiding divide by 0 error\n",
    "        if numerator == 0: continue\n",
    "        denominator += len(entity1_mentions)\n",
    "        # if numerator/denominator > 1:\n",
    "            # print(f\"ERROR: numerator = {numerator} is greater than denominator = {denominator}\")\n",
    "        #     for mention in entity1:\n",
    "        #         pprint(vars(mention))\n",
    "        #     return -1\n",
    "        \n",
    "    \n",
    "    # print(\"WENT THROUGH ALL PAIRS OF ENTITIES....\\n\\n\")\n",
    "    if denominator == 0: return 0\n",
    "    return (numerator/denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metric(metric, entities1, entities2, method=\"binary match\"):\n",
    "    if metric == \"muc\":\n",
    "        return muc(entities1, entities2, method=method)\n",
    "    if metric == \"bcub\":\n",
    "        return b_cubed(entities1, entities2, method=method)\n",
    "    if metric == \"ceafe\":\n",
    "        return ceafe(entities1, entities2, method=method)\n",
    "    if metric == \"lea\":\n",
    "        return lea(entities1, entities2, method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(entities1, entities2, metric, method, verbose=False):\n",
    "    if verbose: print(\"**********\",metric,\"**********\")\n",
    "    # try: \n",
    "    recall = round(evaluate_metric(metric, entities1, entities2, method=method),2)\n",
    "    if verbose: print(\"recall: \",recall)\n",
    "    # except Exception as error: \n",
    "        # print(f\"ERROR IN RECALL: {error}\")\n",
    "    try: \n",
    "        precision = round(evaluate_metric(metric, entities2, entities1, method=method),2)\n",
    "        if verbose: print(\"precision: \",precision)\n",
    "    except Exception as error: \n",
    "         print(f\"ERROR IN PRECISION: {error}\")\n",
    "    try: \n",
    "        f1 = round((2 * recall * precision) / (recall + precision),2)\n",
    "        if verbose: print(\"f1: \",f1)\n",
    "    except: f1 = 0\n",
    "\n",
    "    return {'recall':recall, 'precision':precision, 'f1':f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(key_chains, response_chains, metric='all', method=\"binary match\",verbose=False):\n",
    "\n",
    "    key_entities = [key_chains[key] for key in key_chains.keys()]\n",
    "    response_entities = [response_chains[key] for key in response_chains.keys()]\n",
    "\n",
    "    # print(\"\\n\\ncalculate_metrics entities: \", key_entities)\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    if verbose:\n",
    "        print(\"KEYS:\")\n",
    "        for entity in key_entities:\n",
    "            for mention in entity:\n",
    "                print(vars(mention),\"\\n\")\n",
    "\n",
    "        print(\"\\n\\nRESPONSE:\")\n",
    "        for entity in response_entities:\n",
    "            print(vars(entity[0]),\"\\n\")\n",
    "\n",
    "    if metric == \"all\":\n",
    "\n",
    "        scores['muc'] = get_scores(key_entities, response_entities, \"muc\",method=method, verbose=verbose)\n",
    "        scores['bcubed'] = get_scores(key_entities, response_entities, \"bcub\",method=method, verbose=verbose)\n",
    "        scores['ceafe'] = get_scores(key_entities, response_entities, \"ceafe\",method=method, verbose=verbose)\n",
    "        scores['lea'] = get_scores(key_entities, response_entities, \"lea\",method=method, verbose=verbose)\n",
    "\n",
    "    else: \n",
    "        if metric == 'b_cubed': scores[\"bcubed\"] = get_scores(key_entities, response_entities, \"bcub\",method=method, verbose=verbose)\n",
    "        if metric == 'muc': scores[\"muc\"] = get_scores(key_entities, response_entities, \"muc\",method=method, verbose=verbose)\n",
    "        if metric == 'ceafe': scores[\"ceafe\"] = get_scores(key_entities, response_entities, \"ceafe\",method=method, verbose=verbose)\n",
    "        if metric == 'lea': scores[\"lea\"] = get_scores(key_entities, response_entities, \"lea\",method=method, verbose=verbose)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running for given pair of ground truth and predicted..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# truth = get_conll_input(\"../datasets/coref_model_outputs/235/true/235_final_test_data_true_17.conll\",3,16)\n",
    "# pred = get_conll_input(\"../datasets/coref_model_outputs/235/true/235_final_test_data_true_17.conll\",3,16)\n",
    "truth = get_conll_input(\"../datasets/all_files/true_GT.conll\",3,16)\n",
    "pred = get_conll_input(\"../datasets/all_files/247_ab11_final_test_data_pred.conll\",2,3)\n",
    "# pred = get_conll_input(\"../datasets/conll_files_05_3/pred3_wlcoref.conll\",3,11)\n",
    "# scores = calculate_metrics(truth, pred, method=\"nouns\", metric=\"lea\",verbose=True)\n",
    "scores = calculate_metrics(truth, pred, metric=\"lea\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running for a set of files present in a directory at the same time...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNNING EVALUATOR FOR MULTIPLE FILES, AVERAGING ACROSS THEM\n",
    "import os\n",
    "import pandas as pd\n",
    "def get_averaged_scores(gt_dirpath, pred_dirpath, pred_word_idx, pred_annotation_idx):\n",
    "    scores = {}\n",
    "    for file_name in os.listdir(gt_dirpath):\n",
    "        # print(\"\\n\\n\",file_name)\n",
    "        truth = get_conll_input(gt_dirpath + file_name,3,16)\n",
    "        # file_name = file_name.replace(\"true\",\"pred\")\n",
    "        pred = get_conll_input(pred_dirpath + file_name,pred_word_idx,pred_annotation_idx)\n",
    "        score = calculate_metrics(truth, pred, metric=\"lea\")\n",
    "        scores[file_name] = score['lea']\n",
    "    df = pd.DataFrame(scores)\n",
    "    df = df.transpose()\n",
    "    display(df.mean(axis=0))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recall       0.019286\n",
       "precision    0.170000\n",
       "f1           0.030357\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = get_averaged_scores(\"../datasets/all_files/filewise_split/true_GT/\", \"../datasets/all_files/filewise_split/247_ab11_final_test_data_pred/\", 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recall       0.018214\n",
       "precision    0.241071\n",
       "f1           0.031071\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = get_averaged_scores(\"../datasets/all_files/filewise_split/true2_GT/\", \"../datasets/all_files/filewise_split/247_ab12_final_test_data_pred/\",2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recall       0.004643\n",
       "precision    0.166786\n",
       "f1           0.009286\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = get_averaged_scores(\"../datasets/all_files/filewise_split/true3_GT/\", \"../datasets/all_files/filewise_split/247_ab13_final_test_data_pred/\", 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking Input from model output \n",
    "### model output in required format -  model-mishra-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1730"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"../datasets/model-mishra-format\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': {'binary match': {'bcubed': 1.0, 'muc': 0.11885334770243315, 'ceafe': 0.5875895210527876}, 'words': {'bcubed': 1.0, 'muc': 0.39173646879309965, 'ceafe': 0.7460635287551103}}, 'precision': {'binary match': {'bcubed': 1.0, 'muc': 0.15692453718368354, 'ceafe': 0.5732044249572937}, 'words': {'bcubed': 1.0, 'muc': 0.5558751402808626, 'ceafe': 0.7454180649218175}}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "idx=-1\n",
    "a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r = 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "\n",
    "scores = {'recall':{'binary match':{'bcubed':0,'muc':0,'ceafe':0},'words':{'bcubed':0,'muc':0,'ceafe':0}}, 'precision':{'binary match':{'bcubed':0,'muc':0,'ceafe':0},'words':{'bcubed':0,'muc':0,'ceafe':0}}}\n",
    "\n",
    "for file_idx,filename in enumerate(os.listdir(\"../datasets/model-mishra-format\")):\n",
    "\n",
    "\n",
    "    if \"pred\" in filename: continue\n",
    "\n",
    "\n",
    "    else:\n",
    "        truth = get_input(\"../datasets/model-mishra-format/\"+filename)\n",
    "        pred = get_input(\"../datasets/model-mishra-format/\"+filename.replace('true','pred'))\n",
    "    \n",
    "        # only calculate metrics on non empty chains \n",
    "\n",
    "\n",
    "    # print(\"calculating \", file_idx)\n",
    "    idx += 1\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "        a = calculate_metrics(truth, pred, score='recall',metric='b_cubed', method=\"binary match\")\n",
    "        b = calculate_metrics(truth, pred, score='precicision',metric='b_cubed', method=\"binary match\")\n",
    "\n",
    "        d = calculate_metrics(truth, pred, score='recall',metric='muc', method=\"binary match\")\n",
    "        f = calculate_metrics(truth, pred, score='precicision',metric='muc', method=\"binary match\")\n",
    "\n",
    "        g = calculate_metrics(truth, pred, score='recall',metric='ceafe', method=\"binary match\")\n",
    "        h = calculate_metrics(truth, pred, score='precicision',metric='ceafe', method=\"binary match\")\n",
    "\n",
    "        j = calculate_metrics(truth, pred, score='recall',metric='b_cubed', method=\"word\")\n",
    "        k = calculate_metrics(truth, pred, score='precicision',metric='b_cubed', method=\"word\")\n",
    "\n",
    "        m = calculate_metrics(truth, pred, score='recall',metric='muc', method=\"word\")\n",
    "        n = calculate_metrics(truth, pred, score='precicision',metric='muc', method=\"word\")\n",
    "\n",
    "        p = calculate_metrics(truth, pred, score='recall',metric='ceafe', method=\"word\")\n",
    "        q = calculate_metrics(truth, pred, score='precicision',metric='ceafe', method=\"word\")\n",
    "\n",
    "        scores['recall']['binary match']['bcubed'] += a\n",
    "        scores['precision']['binary match']['bcubed'] += b\n",
    "        scores['recall']['binary match']['muc'] += d\n",
    "        scores['precision']['binary match']['muc'] += f\n",
    "        scores['recall']['binary match']['ceafe'] += g\n",
    "        scores['precision']['binary match']['ceafe'] += h\n",
    "\n",
    "        scores['recall']['words']['bcubed'] += j\n",
    "        scores['precision']['words']['bcubed'] += k\n",
    "        scores['recall']['words']['muc'] += m\n",
    "        scores['precision']['words']['muc'] += n\n",
    "        scores['recall']['words']['ceafe'] += p\n",
    "        scores['precision']['words']['ceafe'] += q\n",
    "\n",
    "    \n",
    "    except:\n",
    "        idx -= 1\n",
    "\n",
    "for k in scores.keys():\n",
    "    for k2 in scores[k].keys():\n",
    "        for k3 in scores[k][k2].keys():\n",
    "            scores[k][k2][k3] /= (idx+1)\n",
    "\n",
    "\n",
    "print(scores)\n",
    "\n",
    "\n",
    "# print(\"METRICS with \", idx+1, \" files\")\n",
    "# print(a/(idx+1),b/(idx+1),d/(idx+1),f/(idx+1),g/(idx+1),h/(idx+1),j/(idx+1),k/(idx+1),m/(idx+1),n/(idx+1),p/(idx+1),q/(idx+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
